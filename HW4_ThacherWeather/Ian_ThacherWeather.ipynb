{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thacher Observatory Weather Data\n",
    "This is an introductory exploration into data wrangling, visualization, and analysis. This notebook will step you through some rudimentary steps leaving the bulk of the exploration up to you.\n",
    "\n",
    "First order of duty is to import all the amazing code that other people have written for our benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clear output\n",
    "# jupyter nbconvert --to notebook --ClearOutputPreprocessor.enabled=True --inplace\n",
    "\n",
    "# Pandas is a very useful python package (read: library, or module) for data acquisition and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib is a large and powerful library for visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "# These commands force plots to be displayed in-line\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# Numpy is another large and powerful library for dealing with math and arithmetic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To look at the attributes and methods of any object use the \"dir\" function.\n",
    "dir(pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us \"load\" a dataset. Loading a dataset is not always as straightforward as one might hope, and the process of getting data into machine readable format, reading the data, and otherwise preparing the data for further analysis is called \"data wrangling.\"\n",
    "\n",
    "In dealing with a dataset that you've never seen before, you might want to start with determining the kind of dataset you are working with. Here are some tips:\n",
    "\n",
    "<ol><li>What kind of extension does the dataset have?</li>\n",
    "<li>Is it binary or ASCII (American Standard Code for Information Interchange)?</li>\n",
    "<li>If it is ASCII, is it a common form: CSV, TXT, XML?</li>\n",
    "<li>If not you may use your favorite editor to look at it.</li>\n",
    "    <ol><li>What delimiters are being used: tab, comma, pipe, etc.?</li></ol>\n",
    "<li>If it is binary, does the extension signify what binary format is being used?</li>\n",
    "<ol><li>Look at online documentation about binary file format.</li>\n",
    "     <li>Look for python package that will help you read that data.</li></ol>\n",
    "</ol>\n",
    "    \n",
    "To start out, let's look at a pretty well behaved dataset. It is the file called WS_data_2014.txt. You can open it with your favorite text editor: TextEdit (Mac), Emacs (cross platform), VI (oldie but goodie), nano (UNIX-like), pico (UNIX-like), etc. This file is simply a text file, so you can even open it from the Home page of you Jupyter session.\n",
    "\n",
    "To read this dataset into python using pandas use the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('WS_data_2014.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at what the function \"read_table\" returned into the variable \n",
    "# (is is actually a pandas DataFrame, which is very much like a python dictionary)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowing our data a little bit better, we could have directed the read_table function a little bit better\n",
    "data = pd.read_csv('WS_data_2014.txt',sep='\\t',\n",
    "                     usecols=[0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],\n",
    "                     skiprows=[0,1],header=0,names=['Date','Time','Heat Index',\n",
    "                                                     'Temp Out','Wind Chill','Hi Temp',\n",
    "                                                     'Low Temp','Hum Out','Dew Pt.','Wind Speed',\n",
    "                                                     'Wind Hi','Wind Dir','Rain','Barometer',\n",
    "                                                     'Temp In','Hum In','Archive'],\n",
    "                    na_values='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it looks like we have all the data we want in a nice, neat DataFrame. How do we access the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a variable that is a pandas series\n",
    "temp = data['Temp Out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the values using this method\n",
    "temp = data['Temp Out'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can do fun and useful appending of dataframe columns to make new dataframes\n",
    "dtDF = data['Date']+' '+data['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime objects are something that we will work with a lot in this class. More to come\n",
    "dt = pd.to_datetime(dtDF).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot_date(dt,temp,'k-')\n",
    "plt.title('Outside Temperature 2014')\n",
    "fig.autofmt_xdate()\n",
    "plt.ylabel('Temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like all the data are there, but you can't see any detail\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot_date(dt,temp,'k-')\n",
    "import datetime\n",
    "plt.xlim([datetime.date(2014, 1, 26), datetime.date(2014, 1, 31)])\n",
    "fig.autofmt_xdate()\n",
    "plt.ylabel('Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we select out only one month of data? Make a new data frame indexed by the date, then it's easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtDFI = pd.DataFrame(temp,columns=['Temp'],index=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtDFI['2014-1':'2014-2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "plt.plot(dtDFI['2014-1-1':'2014-1-10'])\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find all the high and low daily values in January 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = []\n",
    "mins = []\n",
    "for i in np.arange(31)+1:\n",
    "    date = '2014-1-'+str(i)\n",
    "    vals = dtDFI[date].values\n",
    "    try:\n",
    "        maxs = np.append(maxs,np.max(vals))\n",
    "        mins = np.append(mins,np.min(vals))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxhist = plt.hist(maxs,alpha=0.5)\n",
    "minhist = plt.hist(mins,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxhist = plt.hist(maxs,alpha=0.5,bins=np.arange(50)*3,label='Daily Highs')\n",
    "minhist = plt.hist(mins,alpha=0.5,bins=np.arange(50)*3,label='Daily Lows')\n",
    "plt.xlim(30,100)\n",
    "plt.xlabel('Outside Temperature ($^\\circ\\!$F)')\n",
    "plt.legend()\n",
    "plt.title('Temperature Highs/Lows January 2014')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "<ol><li>Load the data from 2015 (WeatherLink_Data_2015.txt). Notice that this is data from another weather station on campus, and is formatted differently.</li>\n",
    "<li>Plot the equivalent plot of the high and low temperatures in January</li>\n",
    "<li>Determine if the mean high and mean low are significantly different from year to year (Hint: You might want to use a <a href='https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.stats.ttest_ind.html' target='_blank'>Welch's T-test</a>, though there are other techniques that we can explore).</li>\n",
    "<li>Export the code in this notebook as python code (File --> Download as --> Python (.py)). Then open that code in spyder (or equivalent IDE), clean it up and make it modular so that weather data from any year can be loaded and visualized</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
