{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram vs. Kernel Density Estimation\n",
    "In this exercise we will get to play with visualizing data as a histogram and also estimating a continuous distribution from a kernel density estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Adapted from: Jake VanderPlas\n",
    " \n",
    " License: BSD\n",
    " \n",
    " For more information, see http://astroML.github.com\n",
    " \n",
    " Start, as always, by importing tools..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a distribution, which is the amalgamation of two different distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = np.concatenate([np.random.normal(-0.5, 0.3, size=14),\n",
    "                    np.random.normal(1, 0.3, size=7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at these data using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.clf()\n",
    "\n",
    "# For uniformity, preassign plot limits\n",
    "XLIM = (-2, 2.9)\n",
    "YLIM = (-0.09, 1.1)\n",
    "\n",
    "# Create custom bins\n",
    "bins = np.linspace(-1.8, 2.7, 13)\n",
    "\n",
    "plt.hist(x, bins=bins, density=True,histtype='stepfilled', fc='k', alpha=0.3)\n",
    "\n",
    "# Make a separator \n",
    "plt.plot(XLIM, [0, 0], '-k', lw=2)\n",
    "plt.plot(x, 0 * x - 0.05, 'ok',markersize=8)\n",
    "plt.xlim(XLIM)\n",
    "plt.ylim(YLIM)\n",
    "plt.xlabel('$x$',fontsize=18)\n",
    "plt.ylabel('$p(x)$',fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, looks pretty good. But if we shift the bins just a little bit, the distribution looks different..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.clf()\n",
    "\n",
    "# Create custom bins\n",
    "bins = np.linspace(-1.8, 2.7, 13)\n",
    "\n",
    "plt.hist(x, bins=bins+0.25, density=True,histtype='stepfilled', fc='k', alpha=0.3)\n",
    "\n",
    "# Make a separator \n",
    "plt.plot(XLIM, [0, 0], '-k', lw=2)\n",
    "plt.plot(x, 0 * x - 0.05, 'ok',markersize=8)\n",
    "plt.xlim(XLIM)\n",
    "plt.ylim(YLIM)\n",
    "plt.xlabel('$x$',fontsize=18)\n",
    "plt.ylabel('$p(x)$',fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can transition to a different approach, namely \"smoothing\" the data with a \"kernel\" which allows one to estimate the probability density of the distribution. Otherwise, aptly called a \"kernel density estimation\" or KDE. \n",
    "\n",
    "We will use sevearal different approaches purely for pedagogical reasons. We start with a \"boxcar average\" which is using a box as the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# First figure: transition to KDE\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "binwidth = bins[1] - bins[0]\n",
    "x_plot = np.linspace(-4, 4, 1000)\n",
    "y_plot = (abs(x_plot - x[:, None]) <= 0.5 * binwidth).astype(float)\n",
    "y_plot /= (binwidth * len(x))\n",
    "plt.fill(x_plot, y_plot.sum(0), ec='k', lw=1, fc='k', alpha=0.3)\n",
    "plt.plot(x_plot, y_plot.T, '-k', lw=1)\n",
    "plt.plot(x, 0 * x - 0.05, 'ok',markersize=8)\n",
    "plt.xlim(XLIM)\n",
    "plt.ylim(YLIM)\n",
    "plt.xlabel('$x$',fontsize=18)\n",
    "plt.ylabel('$p(x)$',fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks kind of funky. But hopefully you get the gist of what is going on...\n",
    "\n",
    "Now lets try a Gaussian (or \"normal\") kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "x_plot = np.linspace(-4, 4, 1000)\n",
    "y_plot = binwidth * stats.norm.pdf(x_plot, x[:, None], 0.1)\n",
    "y_plot /= (binwidth * len(x))\n",
    "plt.fill(x_plot, y_plot.sum(0), ec='k', lw=1, fc='k', alpha=0.3)\n",
    "plt.plot(x_plot, y_plot.T, '-k', lw=1)\n",
    "plt.plot(x, 0 * x - 0.05, 'ok',markersize=8)\n",
    "plt.xlim(XLIM)\n",
    "plt.ylim(YLIM)\n",
    "plt.xlabel('$x$',fontsize=18)\n",
    "plt.ylabel('$p(x)$',fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks alright. But seems like it is a bit peaky for a PDF. Let's try a much wider Gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "binwidth = bins[1] - bins[0]\n",
    "x_plot = np.linspace(-4, 4, 1000)\n",
    "y_plot = binwidth * stats.norm.pdf(x_plot, x[:, None], 0.7)\n",
    "y_plot /= (binwidth * len(x))\n",
    "plt.fill(x_plot, y_plot.sum(0), ec='k', lw=1, fc='k', alpha=0.3)\n",
    "plt.plot(x_plot, 4 * y_plot.T, '-k', lw=1)\n",
    "plt.plot(x, 0 * x - 0.05, 'ok',markersize=8)\n",
    "plt.xlim(XLIM)\n",
    "plt.ylim(YLIM)\n",
    "plt.ylabel('$p(x)$',fontsize=18)\n",
    "plt.xlabel('$x$',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":/ That is clearly not a great representation of the parent distribution from which the data were drawn. Let's hone in on a better width..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "binwidth = bins[1] - bins[0]\n",
    "x_plot = np.linspace(-4, 4, 1000)\n",
    "y_plot = binwidth * stats.norm.pdf(x_plot, x[:, None], 0.2)\n",
    "y_plot /= (binwidth * len(x))\n",
    "plt.fill(x_plot, y_plot.sum(0), ec='k', lw=1, fc='k', alpha=0.3)\n",
    "plt.plot(x_plot, y_plot.T, '-k', lw=1)\n",
    "plt.plot(x, 0 * x - 0.05, 'ok',markersize=8)\n",
    "plt.xlim(XLIM)\n",
    "plt.ylim(YLIM)\n",
    "plt.ylabel('$p(x)$',fontsize=18)\n",
    "plt.xlabel('$x$',fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good! So, there is a bit of an art to choosing the proper kernel width. However, there are some quantitative guidelines for doing this such as Scott's or Silverman's rule of thumb.\n",
    "\n",
    "\n",
    "## Homework\n",
    "1. Check out the <a href=\"https://en.wikipedia.org/wiki/Kernel_density_estimation\">wikipedia page</a> under the Rule of Thumb Bandwidth Estimator section, and calculate the suggested bandwidth for the data above according to the text, and see if it is close to the 0.2 value used in the last plot\n",
    "2. Do a Kernel Density Estimation of the data using the scipy.stats utility called <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html\">gaussian_kde</a>. It is much easier than doing it \"by hand.\" See how the KDE looks in comparison to the last plot. What bandwidth did the program default to using?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
