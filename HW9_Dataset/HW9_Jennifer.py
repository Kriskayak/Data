"""Jennifer YimData AnalysisMidterm Assessment"""import pandas as pdimport matplotlib.pyplot as pltimport numpy as npfrom tqdm import tqdmfrom scipy import statsfrom scipy.stats import normfrom scipy.stats import kstestfrom pandas.plotting import register_matplotlib_convertersimport statsmodelsfrom statsmodels.stats.diagnostic import normal_addf= pd.read_csv("/Users/jennifer/Jen_Data_Science/datasci2020/HW9_Dataset/Jennifer_data.csv", sep=',',                skiprows=[0],header=0,names=['','pless','pfault','ordna','ofault','bin'])df.dtypes#columns:['Unnamed: 0: int64', 'pless: float64' ,'pfault: object' , 'ordna: float64,' , 'ofault: object' , 'bin: int64'], dtype: object#the unnamed column seemes to simply be ordering the data points by number#the two distributions seem to be 'pless' and 'ordna' as they both have a central tendency towards a similar valuedf.shape #554 lines, 6 columns in the data file#"bad values"df.isna()df.isna().sum() #554 useful data points in each column except 549 for 'ordna'df = df.dropna(axis = 0, how = 'any')  #drop rows with any column having np.nan valueslen(df) #549 since we dropped the lines with missing valuesdf.describe()#Lines 42, 135-151, 202, 242, 335, 342, 442 seem like they are "bad" datadf = df[df.pfault != 'n']df = df[df.ofault != 'n']# js - good catch! ^^dist1=df['pless'].valuesdist2=df['ordna'].values##Removing Outliersfrom scipy import statsz = np.abs(stats.zscore(dist1))threshold = 3# js - use your threshold value! Why 3? There are 549 data points!print(np.where(z > 3))z = np.abs(stats.zscore(dist2))threshold = 3print(np.where(z > 3))#returned: array([176, 181, 313])df= df.drop(df.index[[176,181,313]])dist1=df['pless'].valuesdist1.astype('float')dist2=df['ordna'].valuesdist2.astype('float')hist_p = plt.hist(dist1,alpha=0.5,bins=np.arange(50),label='pless')hist_o = plt.hist(dist2,alpha=0.5,bins=np.arange(50),label='ordna')plt.xlim(30,55)plt.xlabel('values')plt.ylabel('frequency')plt.legend()plt.title('Values and Frequencies')# js -looks somewhat Gaussian but both datasets look to be skewed to the left. May have something# to do with your flagging.print (df.describe())##Both the mean and standard deviation vary greatly between the two data sets.#Mean: 41.9 vs. 42.5#Std.:3.0 vs. 3.6print (df.median())##The median seem similar for the two data sets.#41.8 vs. 42.5#Comparison Grahically: Both seem somewhat normalmean,std=norm.fit(dist1)plt.hist(dist1, bins=np.arange(50), density=True)xmin, xmax = plt.xlim(20,60)x = np.linspace(xmin, xmax, 100)y = norm.pdf(x, mean, std)plt.plot(x, y)plt.show()mean,std=norm.fit(dist2)plt.hist(dist2, bins=np.arange(50), density=True)xmin, xmax = plt.xlim(0,100)x = np.linspace(xmin, xmax, 100)y = norm.pdf(x, mean, std)plt.plot(x, y)plt.show()##p-values Interpretationad, p = statsmodels.stats.diagnostic.normal_ad(dist1)print(p)#p=0.98645, very high#Not normal?ad, p = statsmodels.stats.diagnostic.normal_ad(dist2)print(p)#p=0.88638, lower than first but still pretty high##2-variable KS teststats.ks_2samp(dist1, dist2)#KS statistic: 0.113 #p-value: 0.002 -> can reject hypothesis that the distributions come from the same parent #Conclusion: Both of the datasets look normal. By the KS 2-variable test, we can reject the hypothesis that the two datasets come from the same parent as the p-value is given as 0.002, close to 0.'''js comments----------- - Flagging is too aggressive. Hopefully with your sigma rejection HW you    are more familiar with robust methods. - Great plotting! - Solid conclusions based on your final, flagged data. 96/100'''